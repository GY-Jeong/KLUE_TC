{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Validation_confusion.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1lxYa6RdkFvOwAR8g_gxL3KV1VyFWPXj1","authorship_tag":"ABX9TyOKW5rvinFFZ7fbWaq1H6G3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbWmvczoKOwQ","executionInfo":{"status":"ok","timestamp":1627541763953,"user_tz":-540,"elapsed":338,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}},"outputId":"59f9a041-7982-4e8c-dc45-0331521ddecc"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Jul 29 06:56:00 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4kthgVPqr5VC"},"source":["## Directory 설정, 구글 드라이브 import"]},{"cell_type":"code","metadata":{"id":"FOkMqa8hrHl_","executionInfo":{"status":"ok","timestamp":1627541764277,"user_tz":-540,"elapsed":3,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["cur_dir = '/content/drive/MyDrive/KLUE_TC'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jx_d93v9rzQI"},"source":["## Utils"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2KbbvLPitR1N","executionInfo":{"status":"ok","timestamp":1627541774553,"user_tz":-540,"elapsed":10279,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}},"outputId":"8a8ed8f2-f586-4448-c2b2-d1eab0d8ecd1"},"source":["!pip install adamp\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting adamp\n","  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n","Building wheels for collected packages: adamp\n","  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5998 sha256=a1b42e2e190a5a6b21eef44ddf7aa7d452fa5af8b1f70fd83e51e131d8a11e02\n","  Stored in directory: /root/.cache/pip/wheels/bb/95/21/ced2d2cb9944e3a72e58fece7958973eed3fd8d0aeb6e2e450\n","Successfully built adamp\n","Installing collected packages: adamp\n","Successfully installed adamp-0.3.0\n","Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 81.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6oadxEi9rZ7x","executionInfo":{"status":"ok","timestamp":1627541779353,"user_tz":-540,"elapsed":4803,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["import os\n","import random\n","import torch\n","import numpy as np\n","from torch import nn\n","\n","from torch.optim import Adam, AdamW, SGD\n","from adamp import AdamP\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, ExponentialLR, \\\n","    CosineAnnealingWarmRestarts\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n","from sklearn import metrics\n","\n","\n","def set_seeds(seed=42):\n","    # 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def load_tokenizer(args):\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        args.tokenizer_name\n","        if args.tokenizer_name\n","        else args.model_name_or_path,\n","        use_fast=True,\n","    )\n","\n","    return tokenizer\n","\n","\n","def load_model(args, model_name=None):\n","    if not model_name:\n","        model_name = args.model_name\n","    model_path = os.path.join(args.model_dir, model_name)\n","    print(\"Loading Model from:\", model_path)\n","    load_state = torch.load(model_path)\n","    #load_state = torch.load(model_name)\n","\n","    # Load pretrained model and tokenizer\n","    config = AutoConfig.from_pretrained(\n","        args.config_name\n","        if args.config_name\n","        else args.model_name_or_path,\n","    )\n","\n","    config.num_labels = 7\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n","        config=config,\n","    )\n","\n","    model.classifier = nn.Sequential(\n","        nn.Linear(1024, 1024),\n","        nn.Dropout(p=0.3, inplace=False),\n","        nn.Linear(1024, 512),\n","        nn.Dropout(p=0.3, inplace=False),\n","        nn.Linear(512, 7),\n","    )\n","\n","    model.load_state_dict(load_state['state_dict'], strict=True)\n","\n","    model = model.to(args.device)\n","\n","    print(\"Loading Model from:\", model_path, \"...Finished.\")\n","\n","    return model\n","\n","\n","def get_loaders(args, train, valid, is_inference=False):\n","    pin_memory = True\n","    train_loader, valid_loader = None, None\n","\n","    if is_inference:\n","        test_dataset = YNAT_dataset(args, valid, is_inference)\n","        test_loader = torch.utils.data.DataLoader(test_dataset, num_workers=args.num_workers, shuffle=False,\n","                                                  batch_size=args.batch_size, pin_memory=pin_memory)\n","        return test_loader\n","\n","    if train is not None:\n","        train_dataset = YNAT_dataset(args, train, is_inference)\n","        train_loader = torch.utils.data.DataLoader(train_dataset, num_workers=args.num_workers, shuffle=True,\n","                                                   batch_size=args.batch_size, pin_memory=pin_memory)\n","    if valid is not None:\n","        valid_dataset = YNAT_dataset(args, valid, is_inference)\n","        valid_loader = torch.utils.data.DataLoader(valid_dataset, num_workers=args.num_workers, shuffle=False,\n","                                                   batch_size=args.batch_size, pin_memory=pin_memory)\n","\n","    return train_loader, valid_loader\n","\n","\n","# loss계산하고 parameter update!\n","def compute_loss(preds, targets, args):\n","    \"\"\"\n","    Args :\n","        preds   : (batch_size, max_seq_len)\n","        targets : (batch_size, max_seq_len)\n","    \"\"\"\n","    # print(preds, targets)\n","    loss = get_criterion(preds, targets, args)\n","    # 마지막 시퀀스에 대한 값만 loss 계산\n","    # loss = loss[:, -1]\n","    # loss = torch.mean(loss)\n","    return loss\n","\n","\n","def get_criterion(pred, target, args):\n","    if args.criterion == 'BCE':\n","        loss = nn.BCELoss(reduction=\"none\")\n","    elif args.criterion == \"BCELogit\":\n","        loss = nn.BCEWithLogitsLoss(reduction=\"none\")\n","    elif args.criterion == \"MSE\":\n","        loss = nn.MSELoss(reduction=\"none\")\n","    elif args.criterion == \"L1\":\n","        loss = nn.L1Loss(reduction=\"none\")\n","    elif args.criterion == \"CE\":\n","        loss = nn.CrossEntropyLoss()\n","    # NLL, CrossEntropy not available\n","    return loss(pred, target)\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLM-aadds6H9"},"source":["## Dataloader"]},{"cell_type":"code","metadata":{"id":"2s9RxMi7rlfb","executionInfo":{"status":"ok","timestamp":1627541779353,"user_tz":-540,"elapsed":12,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["import os\n","import torch\n","import pandas as pd\n","\n","\n","class Preprocess:\n","    def __init__(self, args):\n","        self.args = args\n","        self.train_data = None\n","        self.test_data = None\n","\n","    def load_data(self, file_name):\n","        csv_file_name = os.path.join(self.args.data_dir, file_name)\n","        df = pd.read_csv(csv_file_name)\n","        #del df['Unnamed: 0']\n","        return df.values\n","\n","    def load_train_data(self):\n","        self.train_data = self.load_data('train_data.csv')\n","\n","    def load_test_data(self):\n","        self.test_data = self.load_data('test_data.csv')\n","\n","\n","class YNAT_dataset(torch.utils.data.Dataset):\n","    def __init__(self, args, data, is_inference):\n","        self.args = args\n","        self.data = data\n","        self.is_inference = is_inference\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        row = self.data[index]\n","        element = [row[i] for i in range(len(row))]\n","        #print(type(row))\n","        # np.array -> torch.tensor 형변환\n","        #for i, col in enumerate(row):\n","        #    if type(col) == str:\n","        #        pass\n","        #    else:\n","        #        row[i] = torch.tensor(col)\n","\n","        return element"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_2g9iLEBtDnJ"},"source":["## Trainer"]},{"cell_type":"code","metadata":{"id":"Xq3sntmNtErb","executionInfo":{"status":"ok","timestamp":1627541908486,"user_tz":-540,"elapsed":312,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["from sklearn.metrics import accuracy_score\n","from torch.nn.functional import one_hot\n","from tqdm import tqdm\n","\n","\n","def run(args, tokenizer, train_data, valid_data, cv_count):\n","    _, valid_loader = get_loaders(args, train_data, valid_data)\n","\n","    if not args.cv_strategy:\n","        model_name = args.run_name\n","    else:\n","        model_name = f\"{args.run_name.split('.pt')[0]}_{cv_count}.pt\"\n","\n","    tokenizer = load_tokenizer(args)\n","\n","    model = load_model(args, model_name)\n","    model.eval()\n","\n","    total_argmax_preds = []\n","    total_ids = []\n","    total_gts = []\n","\n","    for step, batch in tqdm(enumerate(valid_loader), desc='Inferencing', total=len(valid_loader)):\n","        idx, text, label = batch\n","\n","        tokenized_examples = tokenizer(\n","            text,\n","            max_length=args.max_seq_len,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        ).to(args.device)\n","\n","        preds = model(**tokenized_examples)\n","\n","        logits = preds['logits']\n","        logits = logits[:,0,:]\n","        argmax_logits = torch.argmax(logits, dim=1)\n","\n","        if args.device == 'cuda':\n","            argmax_preds = argmax_logits.to('cpu').detach().numpy()\n","            preds = logits.to('cpu').detach().numpy()\n","        else:  # cpu\n","            argmax_preds = argmax_logits.detach().numpy()\n","            preds = logits.detach().numpy()\n","\n","        total_argmax_preds += list(argmax_preds)\n","        total_ids += list(idx)\n","        total_gts += list(label)\n","\n","    target_names = ['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']\n","    print(metrics.classification_report(total_gts, total_argmax_preds, target_names=target_names))\n","    matrix = metrics.confusion_matrix(total_gts, total_argmax_preds)\n","    print(matrix)\n","    print(matrix.diagonal()/matrix.sum(axis=1))"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CS14MP9tFCQ"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"K9DdutwStF4B","executionInfo":{"status":"ok","timestamp":1627541908812,"user_tz":-540,"elapsed":4,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["import torch\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n","from datetime import datetime\n","from pytz import timezone\n","\n","\n","def main(args):\n","    if not args.run_name:\n","        args.run_name = datetime.now(timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d-%H:%M:%S\")\n","\n","    set_seeds(args.seed)\n","\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    args.device = device\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        args.tokenizer_name\n","        if args.tokenizer_name\n","        else args.model_name_or_path,\n","        use_fast=True,\n","    )\n","\n","    preprocess = Preprocess(args)\n","    preprocess.load_train_data()\n","    train_data_origin = preprocess.train_data\n","\n","    print(f\"Size of train data : {len(train_data_origin)}\")\n","    # print(f\"size of test data : {len(test_data)}\")\n","\n","    if args.cv_strategy == 'random':\n","        kf = KFold(n_splits=args.fold_num, shuffle=True)\n","        splits = kf.split(X=train_data_origin)\n","    else:\n","        # default\n","        # 여기 각 label로 바꿔야됨\n","        train_labels = [sequence[-1] for sequence in train_data_origin]\n","        skf = StratifiedKFold(n_splits=args.fold_num, shuffle=True)\n","        splits = skf.split(X=train_data_origin, y=train_labels)\n","\n","    acc_avg = 0\n","    for fold_num, (train_index, valid_index) in enumerate(splits):\n","        train_data = train_data_origin[train_index]\n","        valid_data = train_data_origin[valid_index]\n","        run(args, tokenizer, train_data, valid_data, fold_num + 1)\n","\n","        if not args.cv_strategy:\n","            break"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1EgudubtKjJ"},"source":["## Run"]},{"cell_type":"code","metadata":{"id":"_xupDv9YtKGf","executionInfo":{"status":"ok","timestamp":1627541908812,"user_tz":-540,"elapsed":3,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}}},"source":["import argparse\n","import easydict\n","\n","def parse_args():\n","    args = easydict.EasyDict({'run_name' : 'temp',\n","                             'seed':42,\n","                             'device' :'cuda',\n","                             'data_dir': cur_dir + '/data/open/',\n","                             'model_dir' : '/content/drive/MyDrive/KLUE_TC/models/',\n","                             'model_name_or_path' : 'klue/roberta-large',\n","                             'config_name' : None,\n","                             'tokenizer_name' : None,\n","                             'output_dir' : '/content/drive/MyDrive/KLUE_TC/output/',\n","                             \n","                             'accum_iter' : 4,\n","                             'gradient_accumulation' : True,\n","\n","                             'cv_strategy' : 'stratified',\n","                             'fold_num' : 4,\n","\n","                             'num_workers' : 1,\n","\n","                             # 훈련\n","                             'n_epochs' : 3,\n","                             'batch_size' : 32,\n","                             'lr' : 1e-5,\n","                             'clip_grad' : 10,\n","                             'patience' : 5,\n","                             'max_seq_len' : 40,\n","\n","                             # Optimizer\n","                             'optimizer' : 'adamW',\n","\n","                             # Optimizer-parameters\n","                             'weight_decay' : 0.01,\n","                             'momentum' : 0.9,\n","\n","                             # Scheduler\n","                             'scheduler' : 'step_lr',\n","\n","                             # Scheduler-parameters\n","                             # plateau\n","                             'plateau_patience' : 10,\n","                             'plateau_factor' : 0.5,\n","                              \n","                             't_max' : 10,\n","                             'T_0' : 10,\n","                             'T_mult' : 2,\n","                             '--eta_min' : 0.01,\n","\n","                             # linear_warmup\n","                             'warmup_ratio' : 0.3,\n","\n","                             # Step LR\n","                             'step_size' : 50,\n","                             'gamma' : 0.1,\n","\n","                             'criterion' : 'CE',\n","\n","                             'log_steps' : 100})\n","    \n","    return args"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKuE65Ct3d34","executionInfo":{"status":"ok","timestamp":1627542157010,"user_tz":-540,"elapsed":248201,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}},"outputId":"148aa9dc-6169-4ac2-d788-746ae4f35963"},"source":["if __name__ == '__main__':\n","    args = parse_args()\n","    main(args)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Size of train data : 45654\n","Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_1.pt\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_1.pt ...Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["Inferencing: 100%|██████████| 357/357 [00:48<00:00,  7.41it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        IT과학       0.83      0.88      0.85      1206\n","          경제       0.88      0.82      0.85      1555\n","          사회       0.81      0.79      0.80      1841\n","        생활문화       0.91      0.90      0.90      1483\n","          세계       0.90      0.95      0.93      1908\n","         스포츠       0.96      0.99      0.97      1734\n","          정치       0.94      0.90      0.92      1687\n","\n","    accuracy                           0.89     11414\n","   macro avg       0.89      0.89      0.89     11414\n","weighted avg       0.89      0.89      0.89     11414\n","\n","[[1058   44   51   14   31    5    3]\n"," [ 118 1275  106   16   28    7    5]\n"," [  68   98 1458   81   53   13   70]\n"," [  20   13   83 1332   24    7    4]\n"," [   8   18    6   15 1815   24   22]\n"," [   1    2    1    4    9 1716    1]\n"," [   3    4   91    1   46   18 1524]]\n","[0.87728027 0.81993569 0.79196089 0.89817937 0.95125786 0.98961938\n"," 0.90337878]\n","Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_2.pt\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_2.pt ...Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["Inferencing: 100%|██████████| 357/357 [00:48<00:00,  7.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        IT과학       0.84      0.85      0.85      1206\n","          경제       0.85      0.84      0.85      1556\n","          사회       0.84      0.74      0.79      1841\n","        생활문화       0.89      0.93      0.91      1483\n","          세계       0.91      0.94      0.92      1907\n","         스포츠       0.95      0.99      0.97      1733\n","          정치       0.90      0.92      0.91      1688\n","\n","    accuracy                           0.89     11414\n","   macro avg       0.88      0.89      0.88     11414\n","weighted avg       0.89      0.89      0.89     11414\n","\n","[[1023   69   73   21   11    5    4]\n"," [  97 1311   92   20   24    3    9]\n"," [  58  120 1362  103   57   18  123]\n"," [  18   16   42 1377   21    6    3]\n"," [  10   17    6   19 1789   40   26]\n"," [   5    1    0    4    7 1708    8]\n"," [   1    3   46    6   64    9 1559]]\n","[0.84825871 0.84254499 0.73981532 0.92852326 0.93812271 0.98557415\n"," 0.9235782 ]\n","Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_3.pt\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_3.pt ...Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["Inferencing: 100%|██████████| 357/357 [00:48<00:00,  7.40it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        IT과학       0.83      0.88      0.85      1206\n","          경제       0.87      0.86      0.87      1556\n","          사회       0.82      0.78      0.80      1840\n","        생활문화       0.88      0.92      0.90      1483\n","          세계       0.94      0.93      0.93      1907\n","         스포츠       0.96      0.98      0.97      1733\n","          정치       0.93      0.90      0.92      1688\n","\n","    accuracy                           0.89     11413\n","   macro avg       0.89      0.89      0.89     11413\n","weighted avg       0.89      0.89      0.89     11413\n","\n","[[1066   49   53   21   14    2    1]\n"," [  97 1343   75   17   19    1    4]\n"," [  77  112 1443  102   21   17   68]\n"," [  22    6   74 1366    9    2    4]\n"," [  12   22   20   27 1771   30   25]\n"," [  11    1    3    7    7 1695    9]\n"," [   4   13   93    5   41   11 1521]]\n","[0.88391376 0.86311054 0.78423913 0.92110587 0.9286838  0.97807271\n"," 0.90106635]\n","Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_4.pt\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading Model from: /content/drive/MyDrive/KLUE_TC/models/temp_4.pt ...Finished.\n"],"name":"stdout"},{"output_type":"stream","text":["Inferencing: 100%|██████████| 357/357 [00:48<00:00,  7.39it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        IT과학       0.85      0.85      0.85      1206\n","          경제       0.84      0.86      0.85      1555\n","          사회       0.83      0.77      0.80      1840\n","        생활문화       0.91      0.90      0.90      1484\n","          세계       0.92      0.94      0.93      1907\n","         스포츠       0.96      0.98      0.97      1733\n","          정치       0.92      0.93      0.92      1688\n","\n","    accuracy                           0.89     11413\n","   macro avg       0.89      0.89      0.89     11413\n","weighted avg       0.89      0.89      0.89     11413\n","\n","[[1030   84   57   13   10    9    3]\n"," [  88 1338   76   11   27    4   11]\n"," [  60  128 1419   85   41   15   92]\n"," [  20   17   88 1332   16    5    6]\n"," [  13   26    8   14 1793   27   26]\n"," [   0    2   15    7    3 1702    4]\n"," [   3    6   56    1   50   10 1562]]\n","[0.85406302 0.86045016 0.77119565 0.89757412 0.94022024 0.98211194\n"," 0.92535545]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBuJgScPDFog","executionInfo":{"status":"ok","timestamp":1627543265624,"user_tz":-540,"elapsed":1312,"user":{"displayName":"정근영","photoUrl":"","userId":"04776964382205030605"}},"outputId":"950a6f92-f783-46af-c0b9-81dba76fa564"},"source":["!pip freeze"],"execution_count":14,"outputs":[{"output_type":"stream","text":["absl-py==0.12.0\n","adamp==0.3.0\n","alabaster==0.7.12\n","albumentations==0.1.12\n","altair==4.1.0\n","appdirs==1.4.4\n","argon2-cffi==20.1.0\n","arviz==0.11.2\n","astor==0.8.1\n","astropy==4.2.1\n","astunparse==1.6.3\n","async-generator==1.10\n","atari-py==0.2.9\n","atomicwrites==1.4.0\n","attrs==21.2.0\n","audioread==2.1.9\n","autograd==1.3\n","Babel==2.9.1\n","backcall==0.2.0\n","beautifulsoup4==4.6.3\n","bleach==3.3.0\n","blis==0.4.1\n","bokeh==2.3.3\n","Bottleneck==1.3.2\n","branca==0.4.2\n","bs4==0.0.1\n","CacheControl==0.12.6\n","cached-property==1.5.2\n","cachetools==4.2.2\n","catalogue==1.0.0\n","certifi==2021.5.30\n","cffi==1.14.6\n","cftime==1.5.0\n","chardet==3.0.4\n","charset-normalizer==2.0.2\n","click==7.1.2\n","cloudpickle==1.3.0\n","cmake==3.12.0\n","cmdstanpy==0.9.5\n","colorcet==2.0.6\n","colorlover==0.3.0\n","community==1.0.0b1\n","contextlib2==0.5.5\n","convertdate==2.3.2\n","coverage==3.7.1\n","coveralls==0.5\n","crcmod==1.7\n","cufflinks==0.17.3\n","cupy-cuda101==9.1.0\n","cvxopt==1.2.6\n","cvxpy==1.0.31\n","cycler==0.10.0\n","cymem==2.0.5\n","Cython==0.29.23\n","daft==0.0.4\n","dask==2.12.0\n","datascience==0.10.6\n","debugpy==1.0.0\n","decorator==4.4.2\n","defusedxml==0.7.1\n","descartes==1.1.0\n","dill==0.3.4\n","distributed==1.25.3\n","dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n","dm-tree==0.1.6\n","docopt==0.6.2\n","docutils==0.17.1\n","dopamine-rl==1.0.5\n","earthengine-api==0.1.272\n","easydict==1.9\n","ecos==2.0.7.post1\n","editdistance==0.5.3\n","en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n","entrypoints==0.3\n","ephem==4.0.0.2\n","et-xmlfile==1.1.0\n","fa2==0.3.5\n","fastai==1.0.61\n","fastdtw==0.3.4\n","fastprogress==1.0.0\n","fastrlock==0.6\n","fbprophet==0.7.1\n","feather-format==0.4.1\n","filelock==3.0.12\n","firebase-admin==4.4.0\n","fix-yahoo-finance==0.0.22\n","Flask==1.1.4\n","flatbuffers==1.12\n","folium==0.8.3\n","future==0.16.0\n","gast==0.4.0\n","GDAL==2.2.2\n","gdown==3.6.4\n","gensim==3.6.0\n","geographiclib==1.52\n","geopy==1.17.0\n","gin-config==0.4.0\n","glob2==0.7\n","google==2.0.3\n","google-api-core==1.26.3\n","google-api-python-client==1.12.8\n","google-auth==1.32.1\n","google-auth-httplib2==0.0.4\n","google-auth-oauthlib==0.4.4\n","google-cloud-bigquery==1.21.0\n","google-cloud-bigquery-storage==1.1.0\n","google-cloud-core==1.0.3\n","google-cloud-datastore==1.8.0\n","google-cloud-firestore==1.7.0\n","google-cloud-language==1.2.0\n","google-cloud-storage==1.18.1\n","google-cloud-translate==1.5.0\n","google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n","google-pasta==0.2.0\n","google-resumable-media==0.4.1\n","googleapis-common-protos==1.53.0\n","googledrivedownloader==0.4\n","graphviz==0.10.1\n","greenlet==1.1.0\n","grpcio==1.34.1\n","gspread==3.0.1\n","gspread-dataframe==3.0.8\n","gym==0.17.3\n","h5py==3.1.0\n","HeapDict==1.0.1\n","hijri-converter==2.1.3\n","holidays==0.10.5.2\n","holoviews==1.14.4\n","html5lib==1.0.1\n","httpimport==0.5.18\n","httplib2==0.17.4\n","httplib2shim==0.0.3\n","huggingface-hub==0.0.12\n","humanize==0.5.1\n","hyperopt==0.1.2\n","ideep4py==2.0.0.post3\n","idna==2.10\n","imageio==2.4.1\n","imagesize==1.2.0\n","imbalanced-learn==0.4.3\n","imblearn==0.0\n","imgaug==0.2.9\n","importlib-metadata==4.6.1\n","importlib-resources==5.2.0\n","imutils==0.5.4\n","inflect==2.1.0\n","iniconfig==1.1.1\n","install==1.3.4\n","intel-openmp==2021.3.0\n","intervaltree==2.1.0\n","ipykernel==4.10.1\n","ipython==5.5.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.3.9\n","ipywidgets==7.6.3\n","itsdangerous==1.1.0\n","jax==0.2.17\n","jaxlib @ https://storage.googleapis.com/jax-releases/cuda110/jaxlib-0.1.69+cuda110-cp37-none-manylinux2010_x86_64.whl\n","jdcal==1.4.1\n","jedi==0.18.0\n","jieba==0.42.1\n","Jinja2==2.11.3\n","joblib==1.0.1\n","jpeg4py==0.1.4\n","jsonschema==2.6.0\n","jupyter==1.0.0\n","jupyter-client==5.3.5\n","jupyter-console==5.2.0\n","jupyter-core==4.7.1\n","jupyterlab-pygments==0.1.2\n","jupyterlab-widgets==1.0.0\n","kaggle==1.5.12\n","kapre==0.3.5\n","Keras==2.4.3\n","keras-nightly==2.5.0.dev2021032900\n","Keras-Preprocessing==1.1.2\n","keras-vis==0.4.1\n","kiwisolver==1.3.1\n","korean-lunar-calendar==0.2.1\n","librosa==0.8.1\n","lightgbm==2.2.3\n","llvmlite==0.34.0\n","lmdb==0.99\n","LunarCalendar==0.0.9\n","lxml==4.2.6\n","Markdown==3.3.4\n","MarkupSafe==2.0.1\n","matplotlib==3.2.2\n","matplotlib-inline==0.1.2\n","matplotlib-venn==0.11.6\n","missingno==0.5.0\n","mistune==0.8.4\n","mizani==0.6.0\n","mkl==2019.0\n","mlxtend==0.14.0\n","more-itertools==8.8.0\n","moviepy==0.2.3.5\n","mpmath==1.2.1\n","msgpack==1.0.2\n","multiprocess==0.70.12.2\n","multitasking==0.0.9\n","murmurhash==1.0.5\n","music21==5.5.0\n","natsort==5.5.0\n","nbclient==0.5.3\n","nbconvert==5.6.1\n","nbformat==5.1.3\n","nest-asyncio==1.5.1\n","netCDF4==1.5.7\n","networkx==2.5.1\n","nibabel==3.0.2\n","nltk==3.2.5\n","notebook==5.3.1\n","numba==0.51.2\n","numexpr==2.7.3\n","numpy==1.19.5\n","nvidia-ml-py3==7.352.0\n","oauth2client==4.1.3\n","oauthlib==3.1.1\n","okgrade==0.4.3\n","opencv-contrib-python==4.1.2.30\n","opencv-python==4.1.2.30\n","openpyxl==2.5.9\n","opt-einsum==3.3.0\n","osqp==0.6.2.post0\n","packaging==21.0\n","palettable==3.3.0\n","pandas==1.1.5\n","pandas-datareader==0.9.0\n","pandas-gbq==0.13.3\n","pandas-profiling==1.4.1\n","pandocfilters==1.4.3\n","panel==0.11.3\n","param==1.11.1\n","parso==0.8.2\n","pathlib==1.0.1\n","patsy==0.5.1\n","pexpect==4.8.0\n","pickleshare==0.7.5\n","Pillow==7.1.2\n","pip-tools==4.5.1\n","plac==1.1.3\n","plotly==4.4.1\n","plotnine==0.6.0\n","pluggy==0.7.1\n","pooch==1.4.0\n","portpicker==1.3.9\n","prefetch-generator==1.0.1\n","preshed==3.0.5\n","prettytable==2.1.0\n","progressbar2==3.38.0\n","prometheus-client==0.11.0\n","promise==2.3\n","prompt-toolkit==1.0.18\n","protobuf==3.17.3\n","psutil==5.4.8\n","psycopg2==2.7.6.1\n","ptyprocess==0.7.0\n","py==1.10.0\n","pyarrow==3.0.0\n","pyasn1==0.4.8\n","pyasn1-modules==0.2.8\n","pycocotools==2.0.2\n","pycparser==2.20\n","pyct==0.4.8\n","pydata-google-auth==1.2.0\n","pydot==1.3.0\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","pyemd==0.5.1\n","pyerfa==2.0.0\n","pyglet==1.5.0\n","Pygments==2.6.1\n","pygobject==3.26.1\n","pymc3==3.11.2\n","PyMeeus==0.5.11\n","pymongo==3.11.4\n","pymystem3==0.2.0\n","PyOpenGL==3.1.5\n","pyparsing==2.4.7\n","pyrsistent==0.18.0\n","pysndfile==1.3.8\n","PySocks==1.7.1\n","pystan==2.19.1.1\n","pytest==3.6.4\n","python-apt==0.0.0\n","python-chess==0.23.11\n","python-dateutil==2.8.1\n","python-louvain==0.15\n","python-slugify==5.0.2\n","python-utils==2.5.6\n","pytz==2018.9\n","pyviz-comms==2.1.0\n","PyWavelets==1.1.1\n","PyYAML==5.4.1\n","pyzmq==22.1.0\n","qdldl==0.1.5.post0\n","qtconsole==5.1.1\n","QtPy==1.9.0\n","regex==2019.12.20\n","requests==2.23.0\n","requests-oauthlib==1.3.0\n","resampy==0.2.2\n","retrying==1.3.3\n","rpy2==3.4.5\n","rsa==4.7.2\n","sacremoses==0.0.45\n","scikit-image==0.16.2\n","scikit-learn==0.22.2.post1\n","scipy==1.4.1\n","screen-resolution-extra==0.0.0\n","scs==2.1.4\n","seaborn==0.11.1\n","semver==2.13.0\n","Send2Trash==1.7.1\n","setuptools-git==1.2\n","Shapely==1.7.1\n","simplegeneric==0.8.1\n","six==1.15.0\n","sklearn==0.0\n","sklearn-pandas==1.8.0\n","smart-open==5.1.0\n","snowballstemmer==2.1.0\n","sortedcontainers==2.4.0\n","SoundFile==0.10.3.post1\n","spacy==2.2.4\n","Sphinx==1.8.5\n","sphinxcontrib-serializinghtml==1.1.5\n","sphinxcontrib-websupport==1.2.4\n","SQLAlchemy==1.4.20\n","sqlparse==0.4.1\n","srsly==1.0.5\n","statsmodels==0.10.2\n","sympy==1.7.1\n","tables==3.4.4\n","tabulate==0.8.9\n","tblib==1.7.0\n","tensorboard==2.5.0\n","tensorboard-data-server==0.6.1\n","tensorboard-plugin-wit==1.8.0\n","tensorflow @ file:///tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl\n","tensorflow-datasets==4.0.1\n","tensorflow-estimator==2.5.0\n","tensorflow-gcs-config==2.5.0\n","tensorflow-hub==0.12.0\n","tensorflow-metadata==1.1.0\n","tensorflow-probability==0.13.0\n","termcolor==1.1.0\n","terminado==0.10.1\n","testpath==0.5.0\n","text-unidecode==1.3\n","textblob==0.15.3\n","Theano-PyMC==1.1.2\n","thinc==7.4.0\n","tifffile==2021.7.2\n","tokenizers==0.10.3\n","toml==0.10.2\n","toolz==0.11.1\n","torch @ https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\n","torchsummary==1.5.1\n","torchtext==0.10.0\n","torchvision @ https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\n","tornado==5.1.1\n","tqdm==4.41.1\n","traitlets==5.0.5\n","transformers==4.9.1\n","tweepy==3.10.0\n","typeguard==2.7.1\n","typing-extensions==3.7.4.3\n","tzlocal==1.5.1\n","uritemplate==3.0.1\n","urllib3==1.24.3\n","vega-datasets==0.9.0\n","wasabi==0.8.2\n","wcwidth==0.2.5\n","webencodings==0.5.1\n","Werkzeug==1.0.1\n","widgetsnbextension==3.5.1\n","wordcloud==1.5.0\n","wrapt==1.12.1\n","xarray==0.18.2\n","xgboost==0.90\n","xkit==0.0.0\n","xlrd==1.1.0\n","xlwt==1.3.0\n","yellowbrick==0.9.1\n","zict==2.0.0\n","zipp==3.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P1GetFpEI1iQ"},"source":[""],"execution_count":null,"outputs":[]}]}